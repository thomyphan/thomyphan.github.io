---
layout: archive
author_list: "Thomy Phan and Lenz Belzner and Kyrill Schmid and Thomas Gabor and Fabian Ritz and Sebastian Feld and Claudia Linnhoff-Popien"
title: "A Distributed Policy Iteration Scheme for Cooperative Multi-Agent Policy Approximation"
collection: publications
permalink: /publication/2020-05-01-ala-phan
excerpt: 'We propose Stable Emergent Policy (STEP) approximation, a distributed policy iteration scheme to stably approximate decentralized policies for partially observable and cooperative multi-agent systems. STEP offers a novel training architecture, where function approximation is used to learn from action recommendations of a decentralized planning algorithm. Planning is enabled by exploiting a training simulator, which is assumed to be available during centralized learning, and further enhanced by reintegrating the learned policies. We experimentally evaluate STEP in two challenging and stochastic domains, and compare its performance with state-of-the-art multi-agent reinforcement learning algorithms.'
booktitle: "12th Adaptive and Learning Agents Workshop"
venue_short: "ALA"
date: "2019-05-01"
bibtexid: "phanALA20"
paperurl: "https://ala2020.vub.ac.be/papers/ALA2020_paper_36.pdf"
eprint: "https://thomyphan.github.io/files/2020-ala.pdf"
---

{% include base_path %}

## Related Articles
- T. Phan et al., ["Distributed Policy Iteration for Scalable Approximation of Cooperative Multi-Agent Policies"](https://thomyphan.github.io/publication/2019-05-01-aamas-phan), AAMAS 2019
- T. Phan et al., ["Leveraging Statistical Multi-Agent Online Planning with Emergent Value Function Approximation"](https://thomyphan.github.io/publication/2018-06-01-aamas-phan), ALA 2020
